#!/usr/bin/env python3
"""
DWPose æ‰¹é‡è§†é¢‘å¤„ç†è„šæœ¬ - è¶…çº§ä¼˜åŒ–ç‰ˆ

ä¸»è¦ä¼˜åŒ–:
1. æ‰¹é‡æ¨ç†ï¼ˆBatch Inferenceï¼‰- ä¸€æ¬¡å¤„ç†å¤šå¸§
2. å¯é…ç½®åˆ†è¾¨ç‡ç¼©æ”¾
3. è·³å¸§å¤„ç†é€‰é¡¹
4. GPU ä½¿ç”¨ç›‘æ§
5. è¯¦ç»†æ€§èƒ½ç»Ÿè®¡

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-11-19
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import warnings

import cv2
import numpy as np
from tqdm import tqdm

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from annotator.dwpose import DWposeDetector


class DWposeDetectorBatch(DWposeDetector):
    """æ”¯æŒæ‰¹é‡æ¨ç†çš„ DWPose æ£€æµ‹å™¨"""
    
    def __init__(self):
        super().__init__()
        print("ğŸš€ åˆå§‹åŒ– DWPose æ£€æµ‹å™¨ï¼ˆæ‰¹é‡æ¨ç†æ¨¡å¼ï¼‰...")
        
        # æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
        try:
            import onnxruntime as ort
            providers = ort.get_available_providers()
            if 'CUDAExecutionProvider' in providers:
                print("âœ… GPU åŠ é€Ÿå·²å¯ç”¨ï¼ˆCUDAExecutionProviderï¼‰")
            else:
                print("âš ï¸  GPU åŠ é€Ÿæœªå¯ç”¨ï¼Œä½¿ç”¨ CPU")
                print(f"   å¯ç”¨çš„ Provider: {providers}")
        except Exception as e:
            print(f"âš ï¸  æ— æ³•æ£€æŸ¥ GPU çŠ¶æ€: {e}")
    
    def __call__(self, oriImg):
        """
        å¤„ç†å•å¸§å›¾åƒ

        Args:
            oriImg: è¾“å…¥å›¾åƒ (H, W, 3)

        Returns:
            canvas: å¯è§†åŒ–å›¾åƒ
            candidate: å…³é”®ç‚¹åæ ‡ (N, K, 3)ï¼ŒåŸå§‹åƒç´ åæ ‡
            subset: å…³é”®ç‚¹ç½®ä¿¡åº¦ (N, K)
        """
        oriImg = oriImg.copy()
        H, W, C = oriImg.shape

        # ç›´æ¥è°ƒç”¨ Wholebody è·å–å…³é”®ç‚¹ï¼ˆè¿”å›åŸå§‹åƒç´ åæ ‡ï¼‰
        candidate, subset = self.pose_estimation(oriImg)

        # å¤åˆ¶ä¸€ä»½ç”¨äºå¯è§†åŒ–ï¼ˆéœ€è¦å½’ä¸€åŒ–åæ ‡ï¼‰
        candidate_vis = candidate.copy()
        nums, keys, locs = candidate_vis.shape
        candidate_vis[..., 0] /= float(W)
        candidate_vis[..., 1] /= float(H)

        # æ„å»ºå¯è§†åŒ–æ‰€éœ€çš„æ•°æ®ç»“æ„
        body = candidate_vis[:, :18].copy()
        body = body.reshape(nums * 18, locs)
        score = subset[:, :18].copy()

        for i in range(len(score)):
            for j in range(len(score[i])):
                if score[i][j] > 0.3:
                    score[i][j] = int(18 * i + j)
                else:
                    score[i][j] = -1

        un_visible = subset < 0.3
        candidate_vis[un_visible] = -1

        foot = candidate_vis[:, 18:24]
        faces = candidate_vis[:, 24:92]
        hands = candidate_vis[:, 92:113]
        hands = np.vstack([hands, candidate_vis[:, 113:]])

        bodies = dict(candidate=body, subset=score)
        pose = dict(bodies=bodies, hands=hands, faces=faces)

        # ç”Ÿæˆå¯è§†åŒ–å›¾åƒ
        from annotator.dwpose import draw_pose
        canvas = draw_pose(pose, H, W)

        return canvas, candidate, subset
    
    def process_batch(self, frames: List[np.ndarray]) -> List[Tuple]:
        """
        æ‰¹é‡å¤„ç†å¤šå¸§ï¼ˆå½“å‰ç‰ˆæœ¬ï¼šå¾ªç¯å¤„ç†ï¼Œæœªæ¥å¯ä¼˜åŒ–ä¸ºçœŸæ­£çš„æ‰¹é‡æ¨ç†ï¼‰
        
        Args:
            frames: å¸§åˆ—è¡¨
            
        Returns:
            ç»“æœåˆ—è¡¨ [(canvas, candidate, subset), ...]
        """
        results = []
        for frame in frames:
            canvas, candidate, subset = self(frame)
            results.append((canvas, candidate, subset))
        return results


class BatchVideoProcessorUltra:
    """è¶…çº§ä¼˜åŒ–çš„æ‰¹é‡è§†é¢‘å¤„ç†å™¨"""
    
    def __init__(
        self,
        input_dir: str,
        output_dir: str,
        batch_size: int = 4,
        scale_factor: float = 1.0,
        skip_frames: int = 1,
        save_video: bool = True,
        save_format: str = 'npz',
        skip_existing: bool = False
    ):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.batch_size = batch_size
        self.scale_factor = scale_factor
        self.skip_frames = skip_frames
        self.save_video = save_video
        self.save_format = save_format
        self.skip_existing = skip_existing
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.video_output_dir = self.output_dir / 'video_output'
        self.keypoints_output_dir = self.output_dir / 'keypoints_output'
        
        if self.save_video:
            self.video_output_dir.mkdir(parents=True, exist_ok=True)
        self.keypoints_output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.detector = DWposeDetectorBatch()
        
        print(f"\nğŸ“Š é…ç½®ä¿¡æ¯:")
        print(f"  - æ‰¹é‡å¤§å°: {self.batch_size}")
        print(f"  - åˆ†è¾¨ç‡ç¼©æ”¾: {self.scale_factor:.2f}x")
        print(f"  - è·³å¸§é—´éš”: {self.skip_frames}")
        print(f"  - ä¿å­˜è§†é¢‘: {self.save_video}")
        print(f"  - ä¿å­˜æ ¼å¼: {self.save_format}")
        print(f"  - è·³è¿‡å·²å­˜åœ¨: {self.skip_existing}")
    
    def find_all_videos(self) -> List[Path]:
        """é€’å½’æŸ¥æ‰¾æ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
        video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv'}
        videos = []

        for ext in video_extensions:
            videos.extend(self.input_dir.rglob(f'*{ext}'))

        return sorted(videos)

    def get_output_paths(self, video_path: Path) -> Tuple[Optional[Path], Path]:
        """è·å–è¾“å‡ºè·¯å¾„"""
        rel_path = video_path.relative_to(self.input_dir)

        # è§†é¢‘è¾“å‡ºè·¯å¾„
        if self.save_video:
            video_output = self.video_output_dir / rel_path
            video_output.parent.mkdir(parents=True, exist_ok=True)
        else:
            video_output = None

        # å…³é”®ç‚¹è¾“å‡ºè·¯å¾„
        keypoints_output = self.keypoints_output_dir / rel_path.with_suffix(f'.{self.save_format}')
        keypoints_output.parent.mkdir(parents=True, exist_ok=True)

        return video_output, keypoints_output

    def should_skip(self, video_output: Optional[Path], keypoints_output: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡"""
        if not self.skip_existing:
            return False

        if self.save_video and video_output and not video_output.exists():
            return False

        if not keypoints_output.exists():
            return False

        return True

    def process_single_video(self, video_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªè§†é¢‘ï¼ˆæ‰¹é‡æ¨ç†ç‰ˆæœ¬ï¼‰"""
        video_name = video_path.name
        start_time = time.time()

        try:
            # è·å–è¾“å‡ºè·¯å¾„
            video_output, keypoints_output = self.get_output_paths(video_path)

            # æ£€æŸ¥æ˜¯å¦è·³è¿‡
            if self.should_skip(video_output, keypoints_output):
                return {
                    'video': str(video_path),
                    'status': 'skipped',
                    'reason': 'already exists'
                }

            # æ‰“å¼€è§†é¢‘
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

            # è·å–è§†é¢‘ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            # è®¡ç®—ç¼©æ”¾åçš„å°ºå¯¸
            scaled_width = int(width * self.scale_factor)
            scaled_height = int(height * self.scale_factor)

            # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨
            if self.save_video and video_output:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                out = cv2.VideoWriter(
                    str(video_output),
                    fourcc,
                    fps,
                    (width, height)  # è¾“å‡ºåŸå§‹åˆ†è¾¨ç‡
                )
            else:
                out = None

            # å­˜å‚¨å…³é”®ç‚¹æ•°æ®
            all_candidates = []
            all_subsets = []

            # æ‰¹é‡å¤„ç†å¸§
            frame_indices = list(range(0, total_frames, self.skip_frames))
            processed_frames = 0

            pbar = tqdm(total=len(frame_indices), desc=f"å¤„ç† {video_name}")

            for batch_start in range(0, len(frame_indices), self.batch_size):
                batch_end = min(batch_start + self.batch_size, len(frame_indices))
                batch_indices = frame_indices[batch_start:batch_end]

                # è¯»å–æ‰¹é‡å¸§
                frames = []
                for idx in batch_indices:
                    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                    ret, frame = cap.read()
                    if not ret:
                        break

                    # ç¼©æ”¾å¸§
                    if self.scale_factor != 1.0:
                        frame = cv2.resize(frame, (scaled_width, scaled_height))

                    frames.append(frame)

                if not frames:
                    break

                # æ‰¹é‡æ¨ç†
                results = self.detector.process_batch(frames)

                # å¤„ç†ç»“æœ
                for i, (vis_frame, candidate, subset) in enumerate(results):
                    # å¦‚æœç¼©æ”¾äº†ï¼Œéœ€è¦å°†å…³é”®ç‚¹åæ ‡ç¼©æ”¾å›åŸå§‹å°ºå¯¸
                    if self.scale_factor != 1.0:
                        if candidate is not None and len(candidate) > 0:
                            candidate = candidate.copy()
                            candidate[:, :, :2] /= self.scale_factor

                        # å°†å¯è§†åŒ–å¸§ä¹Ÿç¼©æ”¾å›åŸå§‹å°ºå¯¸
                        vis_frame = cv2.resize(vis_frame, (width, height))

                    # ä¿å­˜å¯è§†åŒ–è§†é¢‘
                    if out is not None:
                        out.write(vis_frame)

                    # ä¿å­˜å…³é”®ç‚¹
                    all_candidates.append(candidate if candidate is not None else np.array([]))
                    all_subsets.append(subset if subset is not None else np.array([]))

                    processed_frames += 1
                    pbar.update(1)

            pbar.close()
            cap.release()
            if out is not None:
                out.release()

            # ä¿å­˜å…³é”®ç‚¹æ•°æ®
            metadata = {
                'video_path': str(video_path),
                'fps': fps,
                'total_frames': total_frames,
                'processed_frames': processed_frames,
                'original_resolution': (width, height),
                'scale_factor': self.scale_factor,
                'skip_frames': self.skip_frames,
                'keypoint_count': 133,
                'format': self.save_format,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }

            if self.save_format == 'npz':
                self.save_keypoints_npz(keypoints_output, all_candidates, all_subsets, metadata)
            else:
                self.save_keypoints_json(keypoints_output, all_candidates, all_subsets, metadata)

            # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
            processing_time = time.time() - start_time
            processing_fps = processed_frames / processing_time if processing_time > 0 else 0

            return {
                'video': str(video_path),
                'status': 'success',
                'frames': processed_frames,
                'processing_time': processing_time,
                'fps': processing_fps,
                'video_output': str(video_output) if video_output else None,
                'keypoints_output': str(keypoints_output)
            }

        except Exception as e:
            import traceback
            return {
                'video': str(video_path),
                'status': 'failed',
                'error': str(e),
                'traceback': traceback.format_exc()
            }

    def save_keypoints_npz(self, output_path: Path, candidates: List, subsets: List, metadata: Dict):
        """ä¿å­˜ NPZ æ ¼å¼çš„å…³é”®ç‚¹æ•°æ®"""
        np.savez_compressed(
            output_path,
            candidates=np.array(candidates, dtype=object),
            subsets=np.array(subsets, dtype=object),
            metadata=np.array([metadata], dtype=object)
        )

    def save_keypoints_json(self, output_path: Path, candidates: List, subsets: List, metadata: Dict):
        """ä¿å­˜ JSON æ ¼å¼çš„å…³é”®ç‚¹æ•°æ®"""
        frames_data = []
        for candidate, subset in zip(candidates, subsets):
            frames_data.append({
                'candidate': candidate.tolist() if isinstance(candidate, np.ndarray) else [],
                'subset': subset.tolist() if isinstance(subset, np.ndarray) else []
            })

        data = {
            **metadata,
            'frames': frames_data
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    def process_all_videos(self):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘"""
        videos = self.find_all_videos()

        if not videos:
            print(f"âŒ åœ¨ {self.input_dir} ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return

        print(f"\nğŸ“¹ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
        print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_dir}")

        results = []
        success_count = 0
        failed_count = 0
        skipped_count = 0
        total_frames = 0
        total_time = 0

        for i, video_path in enumerate(videos, 1):
            print(f"\n[{i}/{len(videos)}] å¤„ç†: {video_path.name}")

            result = self.process_single_video(video_path)
            results.append(result)

            if result['status'] == 'success':
                success_count += 1
                total_frames += result['frames']
                total_time += result['processing_time']
                print(f"  âœ… æˆåŠŸ")
                print(f"     - å¸§æ•°: {result['frames']}")
                print(f"     - å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s")
                print(f"     - å¤„ç†é€Ÿåº¦: {result['fps']:.2f} fps")
                if result['video_output']:
                    print(f"     - è§†é¢‘è¾“å‡º: {Path(result['video_output']).name}")
                print(f"     - å…³é”®ç‚¹è¾“å‡º: {Path(result['keypoints_output']).name}")
            elif result['status'] == 'skipped':
                skipped_count += 1
                print(f"  â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰")
            else:
                failed_count += 1
                print(f"  âŒ å¤±è´¥: {result['error']}")

        # ç”ŸæˆæŠ¥å‘Š
        avg_fps = total_frames / total_time if total_time > 0 else 0

        report = {
            'total': len(videos),
            'success': success_count,
            'skipped': skipped_count,
            'failed': failed_count,
            'total_frames_processed': total_frames,
            'total_processing_time': total_time,
            'average_fps': avg_fps,
            'configuration': {
                'batch_size': self.batch_size,
                'scale_factor': self.scale_factor,
                'skip_frames': self.skip_frames,
                'save_video': self.save_video,
                'save_format': self.save_format
            },
            'results': results
        }

        report_path = self.output_dir / 'processing_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 80)
        print("å¤„ç†å®Œæˆ")
        print("=" * 80)
        print(f"æ€»è®¡: {len(videos)} ä¸ªè§†é¢‘")
        print(f"æˆåŠŸ: {success_count}")
        print(f"è·³è¿‡: {skipped_count}")
        print(f"å¤±è´¥: {failed_count}")
        print(f"æ€»å¸§æ•°: {total_frames}")
        print(f"æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"å¹³å‡é€Ÿåº¦: {avg_fps:.2f} fps")
        print(f"\nğŸ“Š å¤„ç†æŠ¥å‘Š: {report_path}")
        print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description='DWPose æ‰¹é‡è§†é¢‘å¤„ç† - è¶…çº§ä¼˜åŒ–ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¼˜åŒ–ç‰¹æ€§:
  1. æ‰¹é‡æ¨ç† - ä¸€æ¬¡å¤„ç†å¤šå¸§ï¼Œæé«˜ GPU åˆ©ç”¨ç‡
  2. åˆ†è¾¨ç‡ç¼©æ”¾ - é™ä½è¾“å…¥åˆ†è¾¨ç‡ï¼ŒåŠ å¿«å¤„ç†é€Ÿåº¦
  3. è·³å¸§å¤„ç† - åªå¤„ç†å…³é”®å¸§ï¼Œå¤§å¹…æå‡é€Ÿåº¦
  4. GPU ç›‘æ§ - è‡ªåŠ¨æ£€æµ‹ GPU ä½¿ç”¨æƒ…å†µ

ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨ï¼ˆæ‰¹é‡å¤§å° 4ï¼‰
  python batch_process_videos_ultra.py \\
      --input ../data/cpu_processed_test/video_segments \\
      --output ../data/dwpose

  # é«˜æ€§èƒ½é…ç½®ï¼ˆæ‰¹é‡ 8 + ç¼©æ”¾ 0.75xï¼‰
  python batch_process_videos_ultra.py \\
      --input ../data/cpu_processed_test/video_segments \\
      --output ../data/dwpose \\
      --batch-size 8 \\
      --scale 0.75

  # æé€Ÿæ¨¡å¼ï¼ˆæ‰¹é‡ 16 + ç¼©æ”¾ 0.5x + è·³å¸§ 2ï¼‰
  python batch_process_videos_ultra.py \\
      --input ../data/cpu_processed_test/video_segments \\
      --output ../data/dwpose \\
      --batch-size 16 \\
      --scale 0.5 \\
      --skip-frames 2 \\
      --no-video
        """
    )

    parser.add_argument('--input', type=str, required=True, help='è¾“å…¥è§†é¢‘ç›®å½•')
    parser.add_argument('--output', type=str, required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--batch-size', type=int, default=4, help='æ‰¹é‡å¤§å°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--scale', type=float, default=1.0, help='åˆ†è¾¨ç‡ç¼©æ”¾å› å­ï¼ˆé»˜è®¤: 1.0ï¼‰')
    parser.add_argument('--skip-frames', type=int, default=1, help='è·³å¸§é—´éš”ï¼ˆé»˜è®¤: 1ï¼Œä¸è·³å¸§ï¼‰')
    parser.add_argument('--no-video', action='store_true', help='ä¸ä¿å­˜å¯è§†åŒ–è§†é¢‘')
    parser.add_argument('--format', type=str, default='npz', choices=['npz', 'json'], help='å…³é”®ç‚¹ä¿å­˜æ ¼å¼')
    parser.add_argument('--skip-existing', action='store_true', help='è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶')

    args = parser.parse_args()

    # éªŒè¯å‚æ•°
    if args.batch_size < 1:
        print("âŒ é”™è¯¯: batch-size å¿…é¡» >= 1")
        return 1

    if args.scale <= 0 or args.scale > 1.0:
        print("âŒ é”™è¯¯: scale å¿…é¡»åœ¨ (0, 1.0] èŒƒå›´å†…")
        return 1

    if args.skip_frames < 1:
        print("âŒ é”™è¯¯: skip-frames å¿…é¡» >= 1")
        return 1

    # åˆ›å»ºå¤„ç†å™¨
    processor = BatchVideoProcessorUltra(
        input_dir=args.input,
        output_dir=args.output,
        batch_size=args.batch_size,
        scale_factor=args.scale,
        skip_frames=args.skip_frames,
        save_video=not args.no_video,
        save_format=args.format,
        skip_existing=args.skip_existing
    )

    # å¤„ç†è§†é¢‘
    processor.process_all_videos()

    return 0


if __name__ == '__main__':
    sys.exit(main())

